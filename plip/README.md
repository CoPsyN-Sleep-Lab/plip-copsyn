<a id="toc"></a>
# PLIP

PLIP can be divided into 6 different stages.  The stages can be grouped as follows:

Subject-level

  1.) [Preprocessing](#preproc)  
  2.) [PPI](#ppi)  
  3.) [Intrinsic connectivity](#ic)  

Group-level

  4.) [Movement](#movement)  
  5.) [Summary values](#summary)  
  6.) [Biotypes](#biotypes)  

# Subject-level

The processes here run automatically when a new subject is uploaded to Flywheel

<a id="preproc"></a>
### [^](#toc) [Preprocessing](preproc)

`$root/processed/$session/$subject/{anat,func}`

Preprocessing also includes [first level modeling](modeling)

(fMRIPrep integration in progress)  

Images

<a id="05b"></a>
  - `05b_smooth`: Realign/unwarp → slice time corrected → normalized → smoothed (typically 8mm smoothing)

<a id="ppi"></a>
### [^](#toc) [PPI](ppi)

`$root/processed/$session/$subject/func/$task/ppi`

The following explanation of PPI is given by Brooke 

PPI's were initially conceived as a means of identifying regions whose
reponses can be explained in terms of an interaction between activity in
a specified source (the physiological factor) and some experimental
effect (the psychological factor). However, a problem in setting up PPI's
is that in order to derive a proper estimate of the interaction between
a psychological variable (P) and measured hemodynamic signal (x), one 
cannot simply convolve the psychological variable with the hrf (HRF) and 
multiply by the signal. Thus:

                 conv(P,HRF).* x ~= conv((P.*xn),HRF)

P   = psychological variable
HRF = hemodynamic response function
xn  = underlying neural signal which in fMRI is convolved with the hrf to
      give the signal one measures -- x.
x   = measured fmri signal

It is actually the right hand side of the equation one wants.
Thus one has to work backwards, in a sense, and deconvolve the hrf
from x to get xn. This can then be multiplied by P and the resulting
vector (or matrix) reconvolved with the hrf.

This algorithm uses a least squares strategy to solve for xn.

The source's hemodynamics are x = HRF*xn;

Using the constraint that xn should have a uniform spectral density 
we can expand x in terms of a discrete cosine set (xb)

     xn  = xb*B
      B  = parameter estimate

The estimator of x is then

      x  = HRF(k,:)*xn
      x  = HRF(k,:) * xb * B

This accounts for different time resolutions between our hemodynamic 
signal and the discrete representation of the psychological variable. In 
this case k is a vector representing the time resolution of the scans.

Conditional estimates of B allow for priors that ensure uniform variance 
over frequencies.

Once the PPI.ppi interaction term has been calculated a new GLM must be
setup to search for the interaction effects across the brain. This is
done using a standard, first level, fMRI model, which must include 3
covariates, PPI.ppi (interaction), PPI.Y (main effect: source region bold
signal) and PPI.P (main effect: "psychological" condition), plus any
nuisance regressors according to the particular design.

NB: Designs that include only the interaction term without the main
effects are not proper as inferences on the interaction will include a
mixture of both main and interaction effects. 

Once the model has been setup and run, a contrast of [1 0 0 ] over the
PPI.ppi, PPI.Y and PPI.P columns respectively, will show regions with a
positive relationship to the interaction term, discounting any main
effects. Negative regressions can be examined with [-1 0 0]. A PPI random
effects analysis would involve taking the con*.img files from the [1 0 0]
t-contrast for each subject and forwarding them to a second level
analysis.



<a id="ic"></a>
### [^](#toc) [Intrinsic Connectivity](intrinsic_connectivity)

`$root/processed/$session/$subject/ic`

Concatenates into one image the ["05b_smooth"](#05b) files for every task in the ic_tasks defined in the config.  An image is generated by looking at the residuals of a GLM where the nuisance regressors include all the task based stimuli/movement as well as CSF and WM.  The residual image then goes through a filtering process (0.009 - 0.08 Hz).

# Group-level

These scripts are run manually and create summary tables including every subject in the project.

<a id="movement"></a>
### [^](#toc) Movement

`$root/biotypes/dump/movement.csv`

Curate discarded volumes for used in modeling into CSV  

<a id="summary"></a>
### [^](#toc) Summary values

`$root/biotypes/dump`

Betadumps and intrinsic connectivity correlations   

<a id="biotypes"></a>
### [^](#toc) Biotypes

`$root/biotypes/biotype-*.csv`

Biotypes require several steps:

  1.) Gather all the relevant data needed to compute biotypes into one file (see [prep_biotypes.py]())  
  2.) Standardize the generated biotype file against a standardization sample (see []())  
  3.) Calculate biotypes given a formula JSON (see [`biotypes.json`]())
  
For biotype calculations PPI scores are averaged beforehand.  For example, given these masks for PPI, "779062_Left_Amygdala", "426426_Left_10mm_pACC", the biotype formula will calculate `(0.5) * (Left_Amygdala-to-Left_pACC + Left_pACC-to-Left_Amygdala)`
